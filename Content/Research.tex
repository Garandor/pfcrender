\chapter{Research and Architecture Definition}
This section goes into detail on the requirements and discusses possible solutions.
\section{Maintainability}
Maintainability was declared a main goal in the requirements, and this is an issue with much broader reach than just good writing clean code.

Non-coding factors that contribute to maintainability of a software project include
\begin{itemize}
	\item ease of collaboration
	\item issue tracking
	\item early indication of breaking changes
	\item incremental integration of changes with possibility to roll back to an earlier point in history
\end{itemize}

The importance of such "meta-programming" techniques is testified by the fact that a job field for software engineers called \gls{DevOps} exists, which engages in finding ways to optimize coding workflow all day.
A definition of DevOps in \citet{Bass2015}:
\begin{quote}
	DevOps is a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality.
\end{quote}

Though this field is too extensive to thoroughly investigate in the course of a bachelor's thesis, some of these practices are adapted here to make the resulting software maintainable.

In addition to the above, code itself should also conform to certain rules:
\begin{itemize}
	\item encapsulation of functionality in logical units - i.e. classes according to the implementation of \gls{oop} principles in C++
	\item common code formatting guidelines, i.e. making sure code from different contributors "looks the same"
	\item consistent code documentation
\end{itemize}

Adhering to above rules increases productivity of developers and lowers the barrier of entry for new coders.

\subsection{Version Control}
Distributed (even if small in scale) software engineering efforts can greatly benefit from version conttrol systems, which provide features like
\begin{itemize}
	\item Bookkeeping of who authored which change
	\item Messages describing each change (obsoleting Changelogs)
	\item History-keeping of earlier revisions of code
	\item Automatic conflict resolutions in case two developers changed the same files
	\item Maintaining separate states of the code in so-called branches
\end{itemize}

When working on a multi-user project, there really is no excuse for not using some form of \gls{vcs}, as anyone who ever had to manually codebases will attest, but even for single-developer projects they can be very useful, e.g. because the branching feature coupled with change messages allows working on multiple separate features in parallel, only merging changes back to the main program after completion. 


\subsubsection{SVN}
A revisioning software once claiming to be "CVS done right", where CVS is its direct precursor.

It is a  

It has windows integration with TortoiseSVN, making it easy to use
\subsubsection{Mercurial}

\subsubsection{Git}
\gls{git} is a code revisioning software implementation created by Linus Torvalds, searching for a solution to manage the growing base of coders another project of his - the Linux kernel.

Its key benefits are
\begin{description}
	\item[Decentralization] No reliance on availability of a central server for daily work
	\item[Smart Merging] Conflict resolution algorithms are fairly good at finding and automatically fixing trivial conflicts, keeping developer interaction on merges to a minimum
	\item[Central repository support] Though git operates locally, it supports pushing code to and pulling from remote repositories, enabling the use of a central "synchronization" repository, which is the Basis for the popular \gls{github} 
	\item [Huge community] Git has been the prime \gls{vcs} in the \gls{floss} community for several years and brings with it an ecosystem of 3rd-party tool integration 
\end{description}

\subsection{\gls{ci}}
Continuous Integration is a concept popularized as an \gls{agile} method
\subsubsection{Github}

\subsubsection{Jenkins}

\subsection{Code formatting guidelines}
Creating a common code format can be as simple as writing down a set of rules in a code-of-conduct letter for coders to adhere to. What constitutes a "good" formatting guideline is a highly subjective matter however, which is the reason for "different looking code" in the first place.

While it is unlikely that consensus will be reached on coding style in the full C++ community, companies and larger \gls{floss} projects often define guidelines for their employees / contributors,
e.g. the WebKit project\footnote{\url{https://webkit.org/code-style-guidelines/}} and Google\footnote{\url{https://github.com/google/styleguide}}

Though it is possible to manually review every contribution and deny it if it violates code syle guidelines, doing so is unproductively used developer time. Since reformatting code (in the case of C++) simply consists of parsing and reorganizing characters in a text file, it can be automated.

Tools like clang-format\footnote{\url{https://clang.llvm.org/docs/ClangFormat.html}} and astyle\footnote{\url{http://astyle.sourceforge.net/}} exist that - when supplied a formatting contract and source files, automatically reformat the latter.

When used in conjunction with a \gls{vcs}, formatting can be automatically applied before publishing changes (e.g. git pre-commit hook) to other parties, completely abstracting the developer from the process - and thus enabling him to freely disregard code style guidelines during development, without violating them on check-in.

\subsection{Unit Testing frameworks}

"nobody has the time to write tests"

\subsection{Model-driven Design and Round-Trip Engineering}
Modeling is often the first step of implementing a fairly complex architecture, 

decomposing the goal into subobjectives and defining clear interfaces, enabling parallel execution when working in a team.

UML

Models - when, like documentation, manually created - are cumbersome to maintain and keep synchronized with necessary changes to the architecture discovered during implementation.

In classic Model-driven Design, the UML model can be used to generate boilerplate parts of the code (e.g. class / namespace declarations) to save the implementers some work.

Architectural changes made in the code have to be manually introduced in the model as well, which can not be enforced and often leads to the model desyncing. Because of that, often a waterfall model of project design is adopted, where the model is created as a starting point of implementation, and after it has been reviewed and implementation begins, discarded.

Round-Trip Engineering Tooling helps alleviate this problem, by automatically feeding changes from the code back into the UML model.

Depending on the target language, the task of reintroducing changes can be very difficult. C++, being a very syntactically complex language is notoriously difficult to round-trip engineer, reflecting in bad tool support.o

\todo{list of tools that claim to offer c++ rountripping}

- Astah - plugin

\begin{quote}
Theory and practice sometimes clash. And when that happens, theory loses. Every single time.
- Torvalds, Linus (2009-03-25). Message to Linux kernel mailing list. Retrieved on 2009-03-25.
\end{quote}

Since no suitably sophisticated tool could be identified in the noncommercial solutions, round-trip engineering could not be used in this project.

\subsection{Design Patterns}
\subsubsection{Registry Pattern}

\subsubsection{Factory Pattern}

\subsubsection{Builder Pattern}

\subsubsection{Singleton}
Single instance + easy global access from all classes of the app


\subsection{Autogenerated Docs}

\section{Extensibility}

\subsubsection{Plugin Structure}
Lower app startup times, not every importer exporter is needed on every app run

Easy to extend the app with new importers / exporters without touching other internal code

Plugins encapsulated by Shared Libraries can be published to the app, registry of available plugins can be read from config file.

No recompilation needed on adding/removing plugins.

Each plugin must share a common interface though

\subsection{Plugin Architecture}
Looking at the requirements, it is apparent, almost all component have disjunt responsibilities, their main common element being the string description of the PFC they operate on.

The \gls{lsys} generator takes some input and outputs a model string. GUI, SVG and PDF renderings all operate on the model, but don't influence each others operation.

This characteristic is conducive to segregating those components of the app not just to different classes, but to completely separate compilation units, i.e. standalone libraries called plugins.

In conjunction with a dynamic loading system, this confers several benefits:

\begin{itemize}
	\item  Reduced compilation time of the main application
	\item  Extensibility without recompilation
\end{itemize}

This architecture also comes with drawbacks
- Updating the main app with changes breaking public APIs used by plugins will fail at runtime until all plugins have been updated/recompiled
- If plugins have dependencies on other plugins, maintenance complexity grows exponentially and loading sequence must be enforced

The additionally introduced complexity can - in sufficiently complex projects - significantly outweigh modularization benefits, resulting in what is called \"plugin hell\". %\ref @ph.
The Eclipse IDE, in its core being a plugin loader and all functionality supplied by plugins is a prime example of the possible complexity.

Since plugins to pfcrender will mainly consist of new Import/Export formats with limited intrinsic complexity and no dependencies on other plugins, a plugin architecture was deemed beneficial for increasing extensibility and thus the following architecture was chosen.

%\image {Plugin architecture}

\subsection{Configuration}
Main considerations:
- Want all options to be command line selectable
- Want documentation of available commandline options
- Options are provided by components of the GUI as well as by plugins

The main interface to the application will be the commandline.

Automatic documentation of all available options to the commandline is a must-have feature when maintainability of the application is a major concern.

Though other, manual approaches like manfiles and README documents exist, it is not only difficult to prevent them from desynchronizing with the actual code of the program, in a plugin architecture as described above, the actual functionality offered by the total of available plugins will vary by deployment and can thus not be centrally written down.

It was thus decided to introduce a central store of configuration, that will be accessible to the entire application.

Furthermore, each plugin is required to publish configuration options it needs to the main application.

Since all available commandline options must be known at parsing time for documentation generation and parsing itself, it follows that all plugins must be loaded once on startup to query them for their config options.

While this is not computationally efficient, as not all plugins will necessarily be executed during program runtime and thus get loaded in vain, maintainability outweighs this minor performance issue, as the number of plugins is small

\todo{Make callgrind timing analysis of lib calls }

A standard workaround for this issue is builing a list of options at compile time, e.g. using the C++11 constexpr keyword or \gls{tmp}, this method is not suitable here, since options available depend on the available plugins, which are only known at runtime.
See also \url{https://stackoverflow.com/questions/9975672/c-automatic-factory-registration-of-derived-types}
or auto registration of class with a typelist ?
\url{https://stackoverflow.com/questions/42077057/c14-metaprogramming-automagically-build-a-list-of-types-at-compile-init-tim?rq=1}

Another problem is gathering options from plugins automatically is possible when building a list of plugins, options exposed by the main application can not be added this easily, as the objects that expose the info structure do not need to exist by the time. So in this instance - for options of the main app - a manual list must be maintained after all. While this difference in behaviour betwenn core and plugins is unfortunate, it is still an improvement over fully manual API documentation.

For further details on the implementation, see \ref chapterX{Singleton}

This central store can also be exposed to user via the GUI (see \ref chapterX{guiconfig}

\subsection{Batch mode}
Unlike in the GUI, where we can check for config options once the object using them is instantiated, the CLI batch mode runs a preset sequence of steps and needs to gather all available/acceptable config options before starting the process in order to generate meaningful CLI documentation.	

\subsection{config stores}
The selected architecture defines an order of precedence of config options:
1. Global options are set from config file is parsed
2. options given on Command line are set 
(3. GUI options can set config settings)

\section{Cross-OS operation}

Writing portable software has historically been difficult, as operating system \gls{api}s differ significantly. 

Linux and MacOS comply with the \gls{posix} standard, which defines an \gls{api} for system calls, while Windows has historically had a non-\gls{posix}-compliant proprietary system programming \gls{api}.

Recently, Microsoft is making advances towards \gls{posix} compatibility in Win10\furl{https://blogs.msdn.microsoft.com/wsl/2016/04/22/windows-subsystem-for-linux-overview/}, and the Linux world offers a similar compatiblility layer with WINE\furl{https://en.wikipedia.org/w/index.php?title=Wine_(software)&oldid=823689556}. While the performance of the windows POSIX layer is promising\furl{https://www.phoronix.com/scan.php?page=article&item=windows-10-lxcore&num=2}, neither it, nor WINE\furl{https://wiki.winehq.org/Performance} are on par with programs implementing each systems native interface directly at the time of writing.

Supporting the OS native APIs is thus necessary, since good application performance is a requirement.

Notable \gls{api} differences between \gls{posix} and Windows are
\begin{description}
	\item[Library Loading] \gls{posix} Systems use dlopen(), Windows uses LoadLibrary() and different runtime library layouts (.dll on Windows, .so on \gls{posix}
	\item[3D Graphics Backend] Windows mainly uses Microsoft GDI or DirectX and - more recently - AMD Vulkan, while the \gls{posix} world mostly uses OpenGL.
\end{description}

Code depending on any of the above directly is therefore nonportable and the multitude of incompatibilities makes implementing a cross-platform program from-scratch, i.e. without depending on OS-abstracting 3rd-party libraries - an arduous task.

Thankfully, several of those libraries exist that provide a higher-level API abstracting programmers from OS-specific code. They differ wildly in feature-scope, some being abstractions of the graphics layer, some being full-featured cross-OS \gls{gui} toolkits and will be investigated in the following section.

\subsection{Graphics Frameworks Providing OS Abstraction}

\subsubsection{Cairo}
\ref{sec:cairo}
Cairo is a C-based 2D vector graphics library which is widely used in open-source projects\furl{https://en.wikipedia.org/w/index.php?title=Cairo_(graphics)&oldid=812908471} like GTK+, WebKit and the Poppler PDF rendering library.

\subsubsection{SFML}
The C++ written \gls{sfml} library\furl{https://en.wikipedia.org/w/index.php?title=Simple_and_Fast_Multimedia_Library&oldid=820377932} is a relative newcomer to the multi-OS application landscape, with v1 released in 2007.

While its core is a 2D graphics engine, add-ons exist for providing GUI application functionality.  

At the time of writing, it is mainly used in in free or indie game releases.

\subsubsection{SDL}
The \gls{sdl} is a cross-platfrom \gls{hal} library created in 1998, with extensive use in games industry\furl{https://en.wikipedia.org/w/index.php?title=List_of_games_using_SDL&oldid=819037514} to provide 2D \& 3D rendering.

\subsubsection{GTK+}
Unlike above solutions, GTK+\furl{https://en.wikipedia.org/w/index.php?title=GTK\%2B&oldid=822745199}, written in C - is a full GUI application toolkit, providing not only a \gls{hal}, but also graphical control elements, called widgets. Since 2005 it uses cairo (\ref{sec:cairo}) to provide its low-level rendering functionality.

\subsubsection{Qt Framework}
The Qt Framework, like GTK+ is a full-featured GUI application development toolkit and offers extensive functionality.

Like GTK+ it has a widget-based API, but since Qt5 additionally brings a JavaFX-like declarative API called QtQuick.

In addition to providing graphics and \gls{gui} abstractions, it also provides a platform-independent library loading wrapper.
