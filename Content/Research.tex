\chapter{Research and Architecture Definition}

\section{State-of-the Art Development Environment}

Maintainability was declared a main goal in the requirements, and this is an issue with much broader reach than just good programming practice.

It consists of many non-coding factors such as

- ease of collaboration, issue tracking
- enforcing of good coding by-default, e.g. through static analysis
- early indication of breaking changes
- incremental integration or big-bang-release
- ease of code documentation

The importance of such "meta-programming" techniques is testified by the fact, that a job field for software engineers called \gls{DevOps} exists, which engages in finding ways to optimize coding workflow all day.

\subsection{Version Control}

\subsubsection{Git}
\gls{git} is an code revisioning software implementation created by Linus Torvalds, searching for a solution to manage the growing base of coders on his main project - the \gls{linux} kernel.

Its key benefits are
- Decentralization: No reliance on a central server for daily work
- Smart Merging: Conflict resolution algorithms are fairly good at finding and automatically fixing trivial conflicts, keeping developer interaction a merge to a minimum
- Central repository supported: Though git operates locally, it supports pushing code to and pulling from remote repositories, enabling the use of a central "synchronization" repository, which is the Basis for the popular \gls{github} 

\subsubsection{SVN}
A revisioning software once claiming to be "CVS done right", where CVS is its direct precursor.

It is a  
\subsubsection{Mercurial}

\subsection{CI}
Continuous Integration is a concept popularized as an \gls{agile} method
\subsubsection{Github}

\subsubsection{Jenkins}


\subsection{Unit Testing frameworks}

"nobody has the time to write tests"

\subsection{Model-driven Design and Round-Trip Engineering}
Modeling is often the first step of implementing a fairly complex architecture, 

decomposing the goal into subobjectives and defining clear interfaces, enabling parallel execution when working in a team.

UML

Models - when, like documentation, manually created - are cumbersome to maintain and keep synchronized with necessary changes to the architecture discovered during implementation.

In classic Model-driven Design, the UML model can be used to generate boilerplate parts of the code (e.g. class / namespace declarations) to save the implementers some work.

Architectural changes made in the code have to be manually introduced in the model as well, which can not be enforced and often leads to the model desyncing. Because of that, often a waterfall model of project design is adopted, where the model is created as a starting point of implementation, and after it has been reviewed and implementation begins, discarded.

Round-Trip Engineering Tooling helps alleviate this problem, by automatically feeding changes from the code back into the UML model.

Depending on the target language, the task of reintroducing changes can be very difficult. C++, being a very syntactically complex language is notoriously difficult to round-trip engineer, reflecting in bad tool support.o

%TODO: list of tools that claim to offer c++ rountripping

- Astah - plugin


Since no suitably sophisticated tool could be identified in the noncommercial solutions, round-trip engineering could not be used in this project.


\subsection{Autogenerated Docs}


\section{Software Architecture Considerations}

\subsection{Plugin Architecture}
Looking at the requirements, it is apparent, almost all component have disjunt responsibilities, their main common element being the string description of the PFC they operate on.

The \gls{lsys} generator takes some input and outputs a model string. GUI, SVG and PDF renderings all operate on the model, but don't influence each others operation.

This characteristic is conducive to segregating those components of the app not just to different classes, but to completely separate compilation units, i.e. standalone libraries called plugins.

In conjunction with a dynamic loading system, this confers several benefits:

- Reduced compilation time of the main application
- Extensibility without recompilation
- 

This architecture also comes with drawbacks
- Updating the main app with changes breaking public APIs used by plugins will fail at runtime until all plugins have been updated/recompiled
- If plugins have dependencies on other plugins, maintenance complexity grows exponentially and loading sequence must be enforced

The additionally introduced complexity can - in sufficiently complex projects - significantly outweigh modularization benefits, resulting in what is called \"plugin hell\". %\ref @ph.
The Eclipse IDE, in its core being a plugin loader and all functionality supplied by plugins is a prime example of the possible complexity.

Since plugins to pfcrender will mainly consist of new Import/Export formats with limited intrinsic complexity and no dependencies on other plugins, a plugin architecture was deemed beneficial for increasing extensibility and thus the following architecture was chosen.

%\image {Plugin architecture}

\subsection{Configuration}
Main considerations:
- Want all options to be command line selectable
- Want documentation of available commandline options
- Options are provided by components of the GUI as well as by plugins

The main interface to the application will be the commandline.

Automatic documentation of all available options to the commandline is a must-have feature when maintainability of the application is a major concern.

Though other, manual approaches like manfiles and README documents exist, it is not only difficult to prevent them from desynchronizing with the actual code of the program, in a plugin architecture as described above, the actual functionality offered by the total of available plugins will vary by deployment and can thus not be centrally written down.

It was thus decided to introduce a central store of configuration, that will be accessible to the entire application.

Furthermore, each plugin is required to publish configuration options it needs to the main application.

Since all available commandline options must be known at parsing time for documentation generation and parsing itself, it follows that all plugins must be loaded once on startup to query them for their config options.

While this is not computationally efficient, as not all plugins will necessarily be executed during program runtime and thus get loaded in vain, maintainability outweighs this minor performance issue, as the number of plugins is small

%TODO: Make callgrind timing analysis of lib calls 

A standard workaround for this issue is builing a list of options at compile time, e.g. using the C++11 constexpr keyword or \gls{tmp}, this method is not suitable here, since options available depend on the available plugins, which are only known at runtime.
See also \url{https://stackoverflow.com/questions/9975672/c-automatic-factory-registration-of-derived-types}
or auto registration of class with a typelist ?
\url{https://stackoverflow.com/questions/42077057/c14-metaprogramming-automagically-build-a-list-of-types-at-compile-init-tim?rq=1}

Another problem is gathering options from plugins automatically is possible when building a list of plugins, options exposed by the main application can not be added this easily, as the objects that expose the info structure do not need to exist by the time. So in this instance - for options of the main app - a manual list must be maintained after all. While this difference in behaviour betwenn core and plugins is unfortunate, it is still an improvement over fully manual API documentation.

For further details on the implementation, see \ref chapterX{Singleton}

This central store can also be exposed to user via the GUI (see \ref chapterX{guiconfig}

\subsection{Batch mode}
Unlike in the GUI, where we can check for config options once the object using them is instantiated, the CLI batch mode runs a preset sequence of steps and needs to gather all available/acceptable config options before starting the process in order to generate meaningful CLI documentation.	

\subsection{config stores}
The selected architecture defines an order of precedence of config options:
1. Global options are set from config file is parsed
2. options given on Command line are set 
(3. GUI options can set config settings)

\subsection{Performance}
\subsubsection{fxtlib}
\subsubsection{move semantics when operating on model}

\subsection{Cross-Platform Operation}
\subsubsection{Qt Framework}
QApplication, main event loop

\subsubsection{Dynamic Library Loading}
POSIX Systems use dlopen()

Windows uses LoadLibrary()

To get cross-platform operation without recompiling, use Qt's Library loading mechanism: QPluginLoader

\subsubsection{QtQuick}
QML integrate in C++

QRC QtResourceCollection

qml files are not compiled (javascript like)
Actually based on ECMAScript6 aka. JavaScript

declarative as opposed to the imperative  C++

\subsubsection{Signals and Slots in QML}
Signals are captured by invoking Signal Handlers

\subsubsection{Qt and C++1y}
Move semantics not implemented
QQuickItem has disabled copy ctor and no move ctor
use unique\_ptrs to copy without resource leaks


\subsection{Extensibility}
\subsubsection{Plugin Structure}
Lower app startup times, not every importer exporter is needed on every app run

Easy to extend the app with new importers / exporters without touching other internal code

Plugins encapsulated by Shared Libraries can be published to the app, registry of available plugins can be read from config file.

No recompilation needed on adding/removing plugins.

Each plugin must share a common interface though

\section{Design Patterns}
\subsection{Registry Pattern}

\subsection{Factory Pattern}

\subsection{Builder Pattern}

\subsection{Singleton}
Single instance + easy global access from all classes of the app


\section{Problems}
\subsection{Model Creation}
QQuickPaintedItem uses a given painter, explicitly calling functions on it to draw on a paint device.
We want the finished image though, not something that draws based on input. We would need to embed the LSYS string into the model if that were the case.

Und jetzt habe ich die Wahl was ich in der GUI als Modell der PFC speichere, bisherige Überlegungen:
- Den String selbst
Die Ideen sind wohl halbwegs speicheroptimal, müssen aber wohl entweder ein ViewModel zwischengeschaltet bekommen, bevor sie renderbar werden, was den Speichervorteil zunichte macht, oder auf ein Canvasobjekt "gemalt" werden
- Als SVG. Einfach zu rendern, aber den SVG overhead zu parsen ist sicher alles andere als performant.

Model: - 2D - Matrix in der jeder Index ein Segment mit Richtung und Farbe repräsentiert

- Ein QML-Objekt (QQuickPaintedItem), das den LSYS String als member enthält und neu zeichnen lässt (bessere Austauschbarkeit des Modells - nicht limitiert auf PFCs)
- Ein generisches QQuickItem, das als Information direkte OpenGL drawing calls enthält (QSGGeometry)

Das Model muss weiterhin nicht nur als Bitmap renderbar, sondern in verlustfreier Form z.B. nach SVG exportierbar sein - die Daten z.B. nur in einer QSGGeometry vorzuhalten ist praktisch zum rendern (automatisch in Qt), aber unmöglich aus dem Quickitem wieder zu extrahieren


\section{Chosen Application Architecture}

%\figure{fullrequirements.png}



\section{Flexible Buildsystem}
Due to the requirement of a Multi-platform architecture, one of the first considerations is how to get the program code built.

Though it would surely be possible to have the platform agnosstic sources present, and then manually create a project for MSVC/MinGW when on Windows, gnu gcc on Linux and clang on Mac, this would be a pain to set up and maintain.

Solutions to this problem exist in so-called buildsystem generators. Those gather sources, dependencies and additional project information from a configuration file, detect the architecture they are running on, and generate the files necessary to compile the full project on whichever compiler is present on the current system.

QMake - The native buildsystem generator of Qt, uses .pro files for project description

CMake - A powerful and scalable config script-driven generator that is widely used in both Open Source and commercial projects 


\section{Commandline Parsing}
Unlike other programming languages (e.g. Python), C++ does not provide a standard built-in facility to provide parsing capability for parsing parameters passed to the program as commandline options.

Alternatives:

\begin{itemize}
\item getopt() - Coming from C, this is a legacy method widely used on Linux. Since it is specific to POSIX systems, it cannot be used on Windows 
\item Boost.progam\_options - A C++ native, highly configurable solution shipped with the open source Boost library
\url{http://www.boost.org/doc/libs/1\_58\_0/doc/html/program\_options.html}
\item QtCommandLineParser - A Qt native parsing class. Batch-parses all parameters and returns data structures with positional arguments in correct order, and a (reordered) map of switches with their parameters
http://doc.qt.io/qt-5/qcommandlineparser.html
\item Manual parsing of the argv array. While this is the most flexible solution in customization, it is reinventing the wheel and also very inflexible with respect to extensibility.
\end{itemize}

Due to it supporting our use-case, being easily extensible and not introducing any more dependencies into the project above the already used Qt Framework libraries, the QtCommandLineParser was chosen to provide the main CLI-based interface to the program.


\section{Option Persistency}
Since it is often unneccessary to set any and all config options for the program on the command line each time it is run, keeping config options persistently over program relaunches is useful. The typical implementation of this persistent store again varies by platform, ranging from putting keys into the Windows registry, over property list files on Mac to plain .ini or .cfg files on Linux.

Again, Qt comes with a wrapper around this platform disparity
