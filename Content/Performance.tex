\chapter{Application Performance}

\subsection{fxtlib}
\subsection{move semantics when operating on model}
\section{Problems}

\subsection{Angle calculation}
\begin{quote}
Sometimes "pi = 3.14" is (a) infinitely faster than the "correct" answer and (b) the difference between the "correct" and the "wrong" answer is meaningless. And this is why I get upset when somebody dismisses performance issues based on "correctness". The thing is, some specious value of "correctness" is often irrelevant because it doesn't matter. While performance almost always matters. And I absolutely detest the fact that people so often dismiss performance concerns so readily.

- Git mailing list, Fri, 8 Aug 2008
\end{quote}
\subsection{Model Creation}
QQuickPaintedItem uses a given painter, explicitly calling functions on it to draw on a paint device.
We want the finished image though, not something that draws based on input. We would need to embed the LSYS string into the model if that were the case.

Und jetzt habe ich die Wahl was ich in der GUI als Modell der PFC speichere, bisherige Überlegungen:
- Den String selbst
Die Ideen sind wohl halbwegs speicheroptimal, müssen aber wohl entweder ein ViewModel zwischengeschaltet bekommen, bevor sie renderbar werden, was den Speichervorteil zunichte macht, oder auf ein Canvasobjekt "gemalt" werden
- Als SVG. Einfach zu rendern, aber den SVG overhead zu parsen ist sicher alles andere als performant.

Model: - 2D - Matrix in der jeder Index ein Segment mit Richtung und Farbe repräsentiert

- Ein QML-Objekt (QQuickPaintedItem), das den LSYS String als member enthält und neu zeichnen lässt (bessere Austauschbarkeit des Modells - nicht limitiert auf PFCs)
- Ein generisches QQuickItem, das als Information direkte OpenGL drawing calls enthält (QSGGeometry)

Das Model muss weiterhin nicht nur als Bitmap renderbar, sondern in verlustfreier Form z.B. nach SVG exportierbar sein - die Daten z.B. nur in einer QSGGeometry vorzuhalten ist praktisch zum rendern (automatisch in Qt), aber unmöglich aus dem Quickitem wieder zu extrahieren
\subsubsection{QQuickItem + Custom Geometry vs QQuickPaintedItem}
While QQuickPaintedItem allows us to use the QPainter API to generate the model for viewing, which is great, since it is also used by the SVG and PDF exporters, it is also painfully slow, as running callgrind on two parallel implementations shows.
do\_paint, which renders using QPainter API is a factor of 10 slower than manual creation of the OpenGL Vertex/Colordata

IMAGE : Callgrind cost

For this reason, a parallel implementation of both approaches was selected, with the GUI using rendering directly, and Painter based exporters using the QPainter API.

While this means that the GUI viewmodel can not be reused and the curve has to be rebuilt using qpainter on export, the GUI becomes responsive more quickly / scales to more iterates. As far as UX goes, the user can wait for file export, but not for an interactive GUI.
Especially since export is threadable/backgroundable.

\subsubsection{Encapsulation of Functionality (OOP) vs. Method Call overhead}
A lot of the OOP functionalites C++ offers, come at a performance cost.
While some of those classically named ones like stl containers are almost equivalent to plain C data, there are still very costly abstractions present in C++ wwhich can slow down a program significantly.
The gaming world programs C++ without exceptions for this exact reason (TODO: Reference), while those don't come into play here, method call overhead does.


\subsubsection{Runtime Optimization}
When optimizing a program for performance, it is essential to know where in the code the program spends the most time during typical execution, as optimizing 80\% of usecases by 20\% will be much more noticeable by users than speeding up 20\% of usecases by 80\% and is thus a better target for engineering effort.

While measuring the overall execution time of a program is as simple as starting and stopping a timer, looking for timings inside of executable, i.e. at the function level, needs additional instrumentation of the code that is executing. Tools that provide this instrumentation are called application profilers.

%TODO: WHAT DO PROFILERS DO EXACTLY?

One such tool - callgrind - is part of the valgrind analysis suite and well integrated into QtCreator.

\subsubsection{Compiler Optimizations and Inlining}
%TODO: Define stack frame
If a method is simple, but executes a billion times, the cycles spent saving and restoring stack frames while jumping between functions will make up a significant portion of the execution time of the program.

This is where so called inlining can help improve the runtime performance - as with all optimizations - at a cost. The tradeoff in this case being executable size.

Inlining a function means copying the content of its body to the place where it is executed. This skips stack frame saving and a jump/return instruction pair, but (TODO: show assembler of inlined for-loop) leads to the function body being duplicated, i.e. increasing code size with each execution.

While compilers do this type of optimization automatically, a keyword inline exists, that serves as a compiler hint and actually makes gcc/clang more likely to inline a function. Care has to be taken though, since inline has a different meaning when used on a function declaration. (in this case setting the function's definition as local to this translation unit, i.e. other TUs that include the header need to provide their own, identical function definition.

Since - contrary to embedded systems - program space and RAM are usually not a bottleneck on desktop systems, it often makes sense to optimize a program for runtime performance and ignore the larger executable size.

Modern compilers are able to optimize a program by several methods automatically, a user just needs to tell them how much of a tradeoff he is willing to take. The configuration (e.g. on GCC) for this feature is a commandline switch called optimization level. This can be -OS (optimize for size), nothing or -O0 (dont optimize) or -O1 through -O3, optimizing for performance with increasing aggressiveness / tolerance for increses in codesize.

The standard mode for release software is -O2.

\subsubsection{Link-Time Optimization}
Compilers can only optimize on the code they know, i.e. the code in the current translation unit.

Some optimizations (TODO: Which) only become possible when the full program is known, which is link-time. LTO is thus also known as full-program-optimization.

Insead of optimizing on a TU base, it optimizes llvm bytecode (TODO: llvm erkären?)

-flto=full


\subsubsection{Polymorphism and Performance}
Polymorphic classes are a key abstraction of C++ and are distinct from simple inheritance by the presence of the virtual keyword on at least some of their members.

This keyword enables a derived class, referred to through a pointer to the base class to execute its own implementation (a so called override) of the virtual member instead of the one (possibly, but not necessarily) implemented by the base class.

While this mechanism is fundamental to enabling C++ to provide the so called interface abstraction (TODO:Define), it comes with a performance cost.

Calls to a virtual function are not made by directly accessing the address of the callee, but access the so-called vtable instead. which is tasked with resolving the address of the member function.

This introduces several additional cycles (TODO: Measure how many or find in literature), which can become a significant bottleneck for performance, when the virtual function is called often, e.g. in our case, when parsing a character of the model string.

